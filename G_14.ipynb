{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G-14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitsrivastava1608/Transcript-Summarizer/blob/main/G_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYdTAy0STjj"
      },
      "source": [
        "#Installing library for video to audio conversion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBRaSdbqx9M7",
        "outputId": "16623b84-1fe2-41a1-d049-32ec2c322fc7"
      },
      "source": [
        "pip install ffmpeg moviepy"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZP6eWHJSv6d"
      },
      "source": [
        "#Mounting G-Drive for input video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JN1Qkh0ScOK",
        "outputId": "1170c850-eaeb-4135-ca33-1f09025c913c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cSJ8698SqhO"
      },
      "source": [
        "#Video To Audio (moviepy.editor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EYn39iJyD-V"
      },
      "source": [
        "import moviepy.editor as mp"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9voDN_DqXXtW"
      },
      "source": [
        "clip = mp.VideoFileClip(r\"/content/drive/My Drive/G-14/AI.mp4\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvG7DZpJZVkj",
        "outputId": "dfa66bcb-5e23-47da-eb21-6dd1446abfb4"
      },
      "source": [
        "clip.audio.write_audiofile(r\"/content/drive/My Drive/G-14/AIaudio.mp3\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Writing audio in /content/drive/My Drive/G-14/AIaudio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7231/7231 [00:13<00:00, 527.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLp32_ehcqyC"
      },
      "source": [
        "#Audio To Text (Speech Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6s8dKP1TKbp",
        "outputId": "5bb2b0b9-6865-4b8c-9a08-6d737e14aeec"
      },
      "source": [
        "!pip3 install SpeechRecognition pydub\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh8opOOc2G8"
      },
      "source": [
        "Conversion .mp3 to .wav file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-LAnQL1Wm-w",
        "outputId": "0667aaa9-8867-43bd-c63a-1491c13f0458"
      },
      "source": [
        "# import required modules\n",
        "import subprocess\n",
        "\n",
        "# convert mp3 to wav file\n",
        "subprocess.call(['ffmpeg', '-i', '/content/drive/My Drive/G-14/AIaudio.mp3',\n",
        "\t\t\t\t'/content/drive/My Drive/G-14/AIaudio.wav'])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLLfidvDTUj-"
      },
      "source": [
        "import speech_recognition as sr \n",
        "import os \n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st_jgMk-c_cL"
      },
      "source": [
        "#Extracting Text From .wav audio file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3-Vzdgv1bwc"
      },
      "source": [
        "path = \"/content/drive/My Drive/G-14/AIaudio.wav\"\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "def get_large_audio_transcription(path):\n",
        "   \n",
        "   \n",
        "    sound = AudioSegment.from_wav(path)  \n",
        "    chunks = split_on_silence(sound,\n",
        "        \n",
        "        min_silence_len = 500,\n",
        "        \n",
        "        silence_thresh = sound.dBFS-14,\n",
        "       \n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    # process each chunk \n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "       \n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        # recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "            # try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened)\n",
        "            except sr.UnknownValueError as e:\n",
        "                print(\"Error:\", str(e))\n",
        "            else:\n",
        "                text = f\"{text.capitalize()}. \"\n",
        "                print(chunk_filename, \":\", text)\n",
        "                whole_text += text\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0bnJ58h1YpU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "715a9f27-9b98-4049-cfac-d321cd93045c"
      },
      "source": [
        "print(\"\\nFull text:\",get_large_audio_transcription(path))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Picture this. \n",
            "audio-chunks/chunk2.wav : A machine that you organise your cupboard just as you lie. \n",
            "audio-chunks/chunk3.wav : Every member of the house at customised cup of coffee makes your day easier doesn't it these are the products of artificial. \n",
            "audio-chunks/chunk4.wav : But why use the term artificial. \n",
            "audio-chunks/chunk5.wav : Well these machines are artificially incorporated with human-like intelligence to perform tests as we do this intelligent is built using complex algorithms in mathematical functions. \n",
            "audio-chunks/chunk6.wav : But may i may not be as obvious as in the previous examples in fact aye-ayes used in smartphones cars social media feeds videogame banking surveillance and many other aspects of our daily life. \n",
            "audio-chunks/chunk7.wav : The real questionnaires what does an ai do at its core. \n",
            "audio-chunks/chunk8.wav : Here is a real bike with built-in or lamb which is now draught onto a field in spite of a variation in lighting landscape and dimensions of the field the ai robot must perform as expected this ability to react appropriately to a new situation is called generalized. \n",
            "audio-chunks/chunk9.wav : The robot is now at a crossroads. \n",
            "audio-chunks/chunk10.wav : One that is paved in the other rocky the robot must determine which path to take based on the circumstances. \n",
            "audio-chunks/chunk11.wav : This portrays the robots reasoning. \n",
            "audio-chunks/chunk12.wav : After a short straw the robot now and counters the stream that i cannot swim across. \n",
            "audio-chunks/chunk13.wav : Using the plank provided as an input the robot is able to cross the street. \n",
            "audio-chunks/chunk14.wav : So our robot uses the given input and find the solution for prague. \n",
            "audio-chunks/chunk15.wav : This is problem solve. \n",
            "audio-chunks/chunk16.wav : These three capabilities make the robot artificially intelligent. \n",
            "audio-chunks/chunk17.wav : In short ai provides machines with the capability to a day. \n",
            "audio-chunks/chunk18.wav : Reason and provide solutions. \n",
            "audio-chunks/chunk19.wav : Well now that we know what ai is let's have a look at the two broad categories in a eyes classified into. \n",
            "audio-chunks/chunk20.wav : Weak ai also called narrow ai focuses solely on one task. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6b67a90d5349>\u001b[0m in \u001b[0;36mget_large_audio_transcription\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[0;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alternative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownValueError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e79a30b26e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFull text:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_large_audio_transcription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-6b67a90d5349>\u001b[0m in \u001b[0;36mget_large_audio_transcription\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{text.capitalize()}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9WQXDn7dJNw"
      },
      "source": [
        "#The string from video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "QTZYYhKybXI7",
        "outputId": "69d44cd7-635b-4f9a-edf1-9ceba3624819"
      },
      "source": [
        "str=get_large_audio_transcription(path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Picture this. \n",
            "audio-chunks/chunk2.wav : A machine that you organise your cupboard just as you lie. \n",
            "audio-chunks/chunk3.wav : Every member of the house at customised cup of coffee makes your day easier doesn't it these are the products of artificial. \n",
            "audio-chunks/chunk4.wav : But why use the term artificial. \n",
            "audio-chunks/chunk5.wav : Well these machines are artificially incorporated with human-like intelligence to perform tests as we do this intelligent is built using complex algorithms in mathematical functions. \n",
            "audio-chunks/chunk6.wav : But may i may not be as obvious as in the previous examples in fact aye-ayes used in smartphones cars social media feeds videogame banking surveillance and many other aspects of our daily life. \n",
            "audio-chunks/chunk7.wav : The real questionnaires what does an ai do at its core. \n",
            "audio-chunks/chunk8.wav : Here is a real bike with built-in or lamb which is now draught onto a field in spite of a variation in lighting landscape and dimensions of the field the ai robot must perform as expected this ability to react appropriately to a new situation is called generalized. \n",
            "audio-chunks/chunk9.wav : The robot is now at a crossroads. \n",
            "audio-chunks/chunk10.wav : One that is paved in the other rocky the robot must determine which path to take based on the circumstances. \n",
            "audio-chunks/chunk11.wav : This portrays the robots reasoning. \n",
            "audio-chunks/chunk12.wav : After a short straw the robot now and counters the stream that i cannot swim across. \n",
            "audio-chunks/chunk13.wav : Using the plank provided as an input the robot is able to cross the street. \n",
            "audio-chunks/chunk14.wav : So our robot uses the given input and find the solution for prague. \n",
            "audio-chunks/chunk15.wav : This is problem solve. \n",
            "audio-chunks/chunk16.wav : These three capabilities make the robot artificially intelligent. \n",
            "audio-chunks/chunk17.wav : In short ai provides machines with the capability to a day. \n",
            "audio-chunks/chunk18.wav : Reason and provide solutions. \n",
            "audio-chunks/chunk19.wav : Well now that we know what ai is let's have a look at the two broad categories in a eyes classified into. \n",
            "audio-chunks/chunk20.wav : Weak ai also called narrow ai focuses solely on one task. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6b67a90d5349>\u001b[0m in \u001b[0;36mget_large_audio_transcription\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[0;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alternative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownValueError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9233f129bd6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_large_audio_transcription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-6b67a90d5349>\u001b[0m in \u001b[0;36mget_large_audio_transcription\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_listened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{text.capitalize()}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF0DUeMDcEYp"
      },
      "source": [
        "str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uW0pJGkY1Kc"
      },
      "source": [
        "#!pip install gingerit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWFkEj6SYsyV"
      },
      "source": [
        "#from gingerit.gingerit import GingerIt\n",
        "\n",
        "#text = \" Lincoln asia have good skin vitamin e covid-19 important information program.\"\n",
        "\n",
        "#parser = GingerIt()\n",
        "#parser.parse(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWW7YJ0RdcvF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}